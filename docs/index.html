<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Documentation</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Madimi+One&family=Ojuju:wght@200..800&display=swap"
        rel="stylesheet">
</head>

<body>
    <div class="sidebar">
        <div class="sidebar-header">Arachne</div>
        <ul>
            <li><a class="sidebar-main-header" href="#section1">Overview</a></li>
            <li><a class="sidebar-main-header" href="#section2">Getting Started</a></li>
            <li><a class="sidebar-main-header" href="#section3">Codeless setup</a></li>
            <li><a class="sidebar-main-header" href="#section4">Tensor</a></li>
            <li><a class="sidebar-main-header" href="#section5">Model layers</a></li>
            <li><a class="sidebar-main-header" href="#section6">Activation layers</a></li>
            <li><a class="sidebar-main-header" href="#section7">Loss functions</a></li>
            <li><a class="sidebar-main-header" href="#section8">Optimizers</a></li>
            <li><a class="sidebar-main-header" href="#section9">Pipeline</a></li>
            <li><a class="sidebar-main-header" href="#section10">Examples</a></li>

            <!-- Add more section links as needed -->
        </ul>
    </div>
    <div class="content">
        <div class="header">Arachne</div>
        <h1 id="section1">Overview</h1>
        <p>Arachne is a comprehensive deep learning library offering CUDA support for accelerated
            computations on NVIDIA
            GPUs, OpenMP speedup for optimizing performance on multicore CPUs, a full C++ implementation for efficiency
            and control over memory management, and a Python wrapper or API for seamless integration with the extensive
            Python ecosystem. With these features, Arachne provides users with a powerful toolkit for developing and
            deploying deep learning models efficiently, enabling tasks ranging from rapid prototyping to
            high-performance computing environments. Arachne also provides a code free environment to auto create and
            train models on simple datasets(Beta)</p>
        <h1 id="section2">Getting started</h1>
        <p>Clone the GitHub repository given below to install from source</p>
        <code>git clone https://github.com/Aansh2003/Arachne.git</code>
        <p>Go to the build directory</p>
        <code>cd Arachne/server/core/build</code>
        <p>Create the CMake and make the library</p>
        <code>cmake ..</code>
        <br>
        <code>make</code>
        <p>If you want to add a C++ source file, create the file and re initiate the cmake after adding the following
            line to CMakeLists.txt, in the core directory.</p>
        <code>file(GLOB_RECURSE TEST_SOURCES "src/your_file_name.cpp")</code>
        <h1 id="section3">Codeless Setup</h1>
        <p>Configuring the server</p>
        <code>cd Arachne/server</code>
        <br>
        <code>pip3 install -r requirements.txt</code>
        <p>Configuring the client</p>
        <code></code>

        <h1 id="section4">Tensor</h1>
        <p>Constructor definitions - C++</p>
        <p>2D array -> Tensor</p>
        <code>Tensor(T**,std::pair &ltint,int&gt);</code>

        <p>Copy from another Tensor</p>
        <code>Tensor(const Tensor& other);</code>

        <P>Create a tensor with a given default value for a given size</P>
        <code>Tensor(pair<int,int>,T);</code>

        <p>Printing data</p>
        <code>Tensor &ltint&gt a = Tensor &ltint&gt (make_pair(2,2),2);</code><br>
        <code>a.printTensor();</code>
        <p>Operations of Tensors</p>
        <pre>
            <code>
Tensor &ltint&gt a = Tensor &ltint&gt (std::make_pair(2,2),5);
Tensor &ltint&gt b = Tensor &ltint&gt (std::make_pair(2,2),1);

Tensor &ltint&gt sum = a+b;
Tensor &ltint&gt difference = a-b;
Tensor &ltint&gt product = a*b;
</code>
        </pre>

        <p>Converting to float tensors (Useful when using pipelines)</p>
        <pre>
<code>
Tensor &ltint&gt a = Tensor &ltint&gt (std::make_pair(2,2),5);
Tensor &ltfloat&gt b = a.convertFloat();
</code>
        </pre>
        <p>Creating randomized data</p>
        <pre>
Tensor &ltint&gt a = Tensor &ltint&gt randomTensor(make_pair(2,2));
Tensor &ltint&gt b = Tensor &ltint&gt randomTensor(std::make_pair(2,2),10,20); // Random values with minimum of 10 and maximum of 20
Tensor &ltfloat&gt c = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
</pre>
        <p>Data preprocessing (Minimal functionality)</p>
        <p>Normalizing data column wise</p>
        <pre>
<code>
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
a = a.Normalize();
</code>
</pre>
        <p>Flatten Tensor to 1D</p>
        <pre>
<code>
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
a = a.flatten();
</code>
        </pre>
        <p>Reshape to desired size</p>
        <pre>
<code>
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
a = a.reshape(make_pair(4,1));
</code>
        </pre>
        <p>Splitting each row of a Tensor into a new Tensor</p>
        <pre>
<code>
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
vector&ltTensor&ltfloat&gt&gt a_list = a.row_split();
</code>
        </pre>
        <p>Split input and output based on indices</p>
        <pre>
<code>
vector&ltint&gt indices;
indices.push_back(1); // Push back as many column indices are required outputs
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
pair &ltTensor&ltfloat&gt,&ltTensor&ltfloat&gt&gt pair_tensor = a.input_output_split(ind);
</code>
        </pre>
        <p>Transpose Tensor in place</p>
        <pre>
<code>
Tensor &ltfloat&gt a = Tensor &ltfloat&gt randomFloatTensor(make_pair(2,2));
a.transpose();
</code>
        </pre>
        <p>Matrix operation functions</p>
        <pre>
<code>
Tensor &ltint&gt a = Tensor &ltint&gt (std::make_pair(2,2),5);
Tensor &ltint&gt b = Tensor &ltint&gt (std::make_pair(2,2),1);

a = a.multiply(b);
</code>
        </pre>
        <p>All the following operations work in the same way as the previous example.</p>
        <ul>
            <li>OMPmultiply</li>
            <li>elem_multiply</li>
            <li>scalarMultiply</li>
            <li>add</li>
            <li>scalarAdd</li>
            <li>divide</li>
        </ul>
        <h1 id="section5">Model layers</h1>
        <p>Linear</p>
        <p>Trainable layer</p>
    </div>


</body>

</html>